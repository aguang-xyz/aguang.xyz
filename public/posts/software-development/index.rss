<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Software Development</title>
        <link>https://aguang.xyz/#/post/software-development</link>
        <description>Software Development</description>
        <lastBuildDate>Mon, 13 Jul 2020 04:50:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[File Associations in Electron Apps]]></title>
            <link>https://aguang.xyz/#/post/software-development/file-associations-in-electron-apps</link>
            <guid>software-development/file-associations-in-electron-apps</guid>
            <pubDate>Sat, 11 Jul 2020 09:19:01 GMT</pubDate>
            <content:encoded><![CDATA[File Associations in Electron Applications.
Electron is widely used framework by which we
can build cross-platform apps with Javascript, HTML and css. In this article,
I want to introduce a simple way to implement file associations.
Initialize a new Electron Application.
Electron-builder is a
complete solution to package and build a ready-for-distribution Electron app.
A recommended way to create a new Electron application is to clone the template
repository called electron-webpack-quick-start.
git clone https://github.com/electron-userland/electron-webpack-quick-start.git
cd electron-webpack-quick-start
rm -rf .git
File Association Configs.
Electron-builder configuration can be defined in the package.json file of
your project using the build key. And in the common configuration
 section, we can find the definition of key fileAssociations.
fileAssociations Array&ltFileAssociation&gt | FileAssociation - The file associations.
ext String | Array&ltString&gt - The extension (minus the leading period). e.g. png.

name String - The name. e.g. PNG. Defaults to ext.

description String - windows-only. The description.

mimeType String - linux-only. The mime-type.

icon String - The path to icon (.icns for MacOS and .ico for Windows), relative to build (build resources directory). Defaults to ${firstExt}.icns/${firstExt}.ico (if several extensions specified, first is used) or to application icon.
Not supported on Linux, file issue if need (default icon will be `x-office-document`).

role = Editor String - macOS-only The app’s role with respect to the type. The value can be Editor, Viewer, Shell, or None. Corresponds to CFBundleTypeRole.

isPackage Boolean - macOS-only Whether the document is distributed as a bundle. If set to true, the bundle directory is treated as a file. Corresponds to LSTypeIsPackage.

protocols Array&ltProtocol&gt | Protocol - The URL protocol schemes.

name String - The name. e.g. IRC server URL.

schemes Array&ltString&gt - The schemes. e.g. [&ampquot;irc&ampquot;, &ampquot;ircs&ampquot;].

role = Editor “Editor” | “Viewer” | “Shell” | “None” - macOS-only The app’s role with respect to the type.





The above is an example to support file association of markdown files.
By this, electron-builder will automatically:
Write related configs into window registry for Windows. 
Generate related configs into Info.plist for macOS. 
Generate field MimeType = text/markdown in your application.desktop for Linux.

&quotbuild&quot: {
    &quotfileAssociations&quot: [{
        &quotext&quot: &quotmd&quot,
        &quotdescription&quot: &quotMarkdown File&quot,
        &quotmimeType&quot: &quottext/markdown&quot,
        &quotname&quot: &quotMarkdown File&quot,
        &quotrole&quot: &quotEditor&quot
    }]
},
Handle File Opening.
There are different ways to trigger file opening via your application:
On macOS, an open-file event will be triggered as mentioned here;
and to successfully handle this event, we should call event.preventDefault().

On Linux or Windows, a new process will be executed and we can get the file path via process.argv.


The code above shows how to handle file opening for all platforms.
import { app } from &quotelectron&quot;

// Handle file opening for macOS.
app.on(&quotopen-file&quot, (event, path) =&gt {

    // Notify the framework, this event has been handled.
    event.preventDefault();

    handleOpen(path);
});

app.on(&quotready&quot, () =&gt {

    // TODO: Initialize your application.

    // Handle file opening for Windows and Linux.
    if (process.argv[1]) {

        // Since we may have extra parameters (e.g. app --sanbox), process.argv[1]
        // may not be an existed file path, we should catch potential exceptions
        // here.    
        try {
            handleOpen(process.argv[1]);
        }    catch (err) {
            console.warn(`Failed to open ${path}: ${err.message}`);
        }
    }
});
References.
Electron: build cross-platform desktop apps with JavaScript, HTML, and CSS.
Electron-builder: a complete solution to package and build a ready for distribution Electron.
Electron-webpack-quick-start: a bare minimum project structure to get started developing Electron app.
Windows Registry. In Wikipedia, The Free Encyclopedia.

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Automatic Captioning in Python]]></title>
            <link>https://aguang.xyz/#/post/software-development/auto-captioning-in-python</link>
            <guid>software-development/auto-captioning-in-python</guid>
            <pubDate>Tue, 23 Jun 2020 04:50:08 GMT</pubDate>
            <content:encoded><![CDATA[Automatic Captioning in Python.
System: Ubuntu 18.04
Python: 3.6

There are many cloud-based speech recognization services available
(etc. Google Cloud, IBM Watson, Microsoft Azure, Wit.ai). But in this article, I&amp#39;m gonna introduce the way how to achieve auto-captioning fully offline step by step.

Briefly, this program contains several parts:
Extracting the audio from the input video.
Converting from stereo waveforms to single mono waveform.
Speech recognization based on vosk, extracting words and their positions (start time and end time) from the mono waveform.
Segment words into sentences based on NNSplit.

Vosk is an offline speech recognition library based on Kaldi. And NNSplit is a library by which we can split words into sentences without punctuations based on a sequence labeling LSTM.
Audio Extracting.
The first step is quite simple, we can import the library moviepy which provides the API to extract audios from videos based on ffmpeg.
Install ffmpeg and moviepy.
sudo apt install ffmpeg
pip3 install moviepy
Extract audio.
from moviepy.editor import VideoFileClip

def extract_audio(video_path, wav_path):  
    video = VideoFileClip(video_path)
  video.audio.write_audiofile(wav_path)
Stereo Waveforms Combining.
The wav file written by moviepy may contain multiple stereo channels. Now we use pydub to combine these channels to a single mono channel.

Install pydub.
pip3 install pydub
Combine stereo channels.
from pydub import AudioSegment

def combine_stereos(wav_path):
    audio = AudioSegment.from_file(wav_path)
    channels = audio.split_to_mono()
    sum(channels).export(wav_path, format=&quotwav&quot)
Speech Recognization.
Vosk is a speech recognization library which supports 9 languages and works offline based on kaldi. By default, it takes small model to work on lightweight devices. To achive higher accuracy, we can download bigger server models from here. We use wave to parse the wav file and read binary frames to feed vosk. Since the speech recognization may take a quite long time, we use tqdm to show a progress bar.
Install [vosk][https://alphacephei.com/vosk/] and tqdm.
pip3 install vosk tqdm
Recognize speech.
def recognize_speech(wav_path, lang=&quoten&quot, buffer_size=4000):

  vosk.SetLogLevel(-1)

  wav_file = wave.open(wav_path, &quotrb&quot)
  recognizer = vosk.KaldiRecognizer(vosk.Model(&quotmodel/{}&quot.format(lang)),
                                    wav_file.getframerate())
  words = []

  for index in tqdm(range(0, wav_file.getnframes(), buffer_size)):
      frames = wav_file.readframes(buffer_size)

      if recognizer.AcceptWaveform(frames):
          result = json.loads(recognizer.Result())

          if len(result[&quottext&quot]) &gt 0:
            for token in result[&quotresult&quot]:
              words.append({
                  &quotstart&quot: token[&quotstart&quot],
                  &quotend&quot: token[&quotend&quot],
                  &quottext&quot: token[&quotword&quot],
              })

  return words
After speech recognization, we can get a sort of words and their positions (start time and end time) in the given, like this:

Sentence Segmentation.
Now the next problem is that we don&amp#39;t have punctuations to split the words into sentences easily. This problem is as known as Sentence boundary disambiguation (SBD). NNSplit is such a library that aims split words into sentences without punctuations based on a sequence labeling LSTM.
Words to Sentences.
yeah but you just got out of prison /
i mean how much of a step up from that /
you don&#39t get out of the booth
Install NNSplit.
pip3 install nnsplit
Segment sentences.
def segment_setences(words, lang=&quoten&quot):

    content = &quot &quot.join(map(lambda word: word[&quottext&quot], words))
  sentences = []

  left = 0

  for tokens2d in tqdm(nnsplit.NNSplit(lang).split([content])):
    for tokens in tokens2d:

      text = &quot&quot.join(
        map(lambda token: token.text + token.whitespace, tokens)).strip()

      right = min(len(words), left + len(tokens)) - 1

      while right &gt 0 and not text.endswith(words[right][&quottext&quot]):
        right -= 1

      sentences.append({
        &quotstart&quot: words[left][&quotstart&quot],
        &quotend&quot: words[right][&quotend&quot],
        &quottext&quot: text
      })

      left = right + 1

  return sentences
Example result of sentence segmentation:

SRT File Generation.
The final step is quite easy. Now we want to write the result into a format which can detected by video player automatically. SubRip Subtitle Format could be a good chioce.
A .srt file is a pure text file with sequence numbers starting from 1, timestamps and caption texts. The content below shows what a .srt file looks like:
1
00:00:00,210 --&gt 00:00:01,650
yeah but you just got out of prison

2
00:00:01,650 --&gt 00:00:03,870
i mean how much of a step up from that

3
00:00:03,930 --&gt 00:00:04,830
you don&#39t get out of the booth

...

Generate SRT file.
def time2str(x):

  return &quot{hour:02d}:{minute:02d}:{second:02d},{millisecond}&quot.format(
    hour=int(x) // 3600,
    minute=(int(x) // 60) % 60,
    second=int(x) % 60,
    millisecond=int(x * 1000) % 1000)

def write_srt_file(captions, srt_path):

  with open(srt_path, &quotw&quot) as srt_file:
    for index, caption in enumerate(captions):
      srt_file.write(&quot{}\n{} --&gt {}\n{}\n\n&quot.format(
        index + 1, time2str(caption[&quotstart&quot]),
        time2str(caption[&quotend&quot]), caption[&quottext&quot]))
Conclusion.
In this article I&amp#39;ve introduced a way to implement a fully offline program automatically generating captions from videos.
This sample shows the captions generated from my program. And I&amp#39;ve published the implementation as a Python package called auto-caption.
References.
Build Natural Language Expeiences with Wit.ai.
FFMpeg - A complete, cross-platform solution to record, convert and stream audio and video.
Fast, robust sentence splitting with bindings for Python, Rust and Javascript.
Kaldi Speech Recognization Toolkit.
MoviePy - A python module for movie editing.
Pydub - Manipulate audio with a simple and easy high level interface.
Sentence boundary disambiguation.
Speech to Text with Google Cloud.
Speech to Text with IBM Watson.
Speech to Text with Microsoft Azure.
SubRip Subtitle Format.
TQDM - A Fast, Extensible Progress Bar for Python and CLI.
VOSK Speech Recognization API.

]]></content:encoded>
        </item>
    </channel>
</rss>